{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magic Gamma Telescope Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"magic04.data\",delimiter=',',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fLength    fWidth   fSize   fConc  fConc1     fAsym  fM3Long  fM3Trans  \\\n",
      "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110   -8.2027   \n",
      "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238   -9.9574   \n",
      "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580  -45.2160   \n",
      "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633   -7.1513   \n",
      "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525   21.8393   \n",
      "\n",
      "    fAlpha     fDist  target  \n",
      "0  40.0920   81.8828       1  \n",
      "1   6.3609  205.2610       1  \n",
      "2  76.9600  256.7880       1  \n",
      "3  10.4490  116.7370       1  \n",
      "4   4.6480  356.4620       1  \n"
     ]
    }
   ],
   "source": [
    "data.columns = ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym', 'fM3Long', 'fM3Trans', 'fAlpha', 'fDist', 'target']\n",
    "data['target']=data['target'].map({'g':1,'h':0}).values\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    6688\n",
      "1    6688\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_h=data[data['target']==0]\n",
    "class_g=data[data['target']==1]\n",
    "numofh=class_h.shape[0]\n",
    "class_g_balanced = resample(class_g, replace=False,n_samples=numofh,random_state=42) \n",
    "data_balanced=pd.concat([class_h,class_g_balanced])\n",
    "print(data_balanced['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 9363\n",
      "Validation set size: 2006\n",
      "Testing set size: 2007\n"
     ]
    }
   ],
   "source": [
    "features=data_balanced.drop('target',axis=1)\n",
    "targets=data_balanced['target']\n",
    "features_train,features_vald_test,target_train,target_vald_test=train_test_split(features,targets,test_size=0.3)\n",
    "features_vald,features_test,target_vald,target_test=train_test_split(features_vald_test,target_vald_test,test_size=0.5)\n",
    "print(f'Training set size: {features_train.shape[0]}')\n",
    "print(f'Validation set size: {features_vald.shape[0]}')\n",
    "print(f'Testing set size: {features_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=StandardScaler()\n",
    "features_train = scale.fit_transform(features_train)\n",
    "features_vald = scale.transform(features_vald)\n",
    "features_test = scale.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for k in range(1,21,3):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(features_train,target_train)\n",
    "    target_predict=knn.predict(features_vald)\n",
    "    accuarcy=accuracy_score(target_vald,target_predict)\n",
    "    class_report = classification_report(target_vald, target_predict,output_dict=True)\n",
    "    conf_matrix = confusion_matrix(target_vald, target_predict)\n",
    "    precision = class_report['1']['precision']\n",
    "    recall = class_report['1']['recall']\n",
    "    f1_score = class_report['1']['f1-score']\n",
    "    results.append({\n",
    "        'k': k,\n",
    "        'Accuracy': accuarcy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1_score,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('knn_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
